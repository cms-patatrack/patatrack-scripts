#! /usr/bin/env python

import sys
import os
import copy

from multirun import *


if __name__ == "__main__":
  if not 'CMSSW_BASE' in os.environ:
    # FIXME print a meaningful error message
    sys.exit(1)

  # TODO parse arguments and options from the command line
  if len(sys.argv) > 1:
    config = sys.argv[1]
    process = parseProcess(config)
  else:
    # FIXME print a meaningful error message
    sys.exit(1)

  # options passed to multiCmsRun
  options = {
    'verbose'             : False,
    'plumbing'            : False,
    'warmup'              : True,
    'events'              : 4100,
    'repeats'             : 4,
    'jobs'                : 1,          # if None, set the number of jobs to fill all available CPUs
    'threads'             : None,       # if None, overridden by the scan
    'streams'             : None,       # if None, overridden by the scan
    'gpus_per_job'        : 1,
    'allow_hyperthreading': False,      # this determined the number and afifnity of the CPUs used by each job
    'set_cpu_affinity'    : True,
    'set_gpu_affinity'    : True,
    'logdir'              : None,       # relative or absolute path, or None to disable storing the logs
    'keep'                : [],         # list of files produced by the jobs to be kept (requires logdir)
  }

  run_io_benchmark = False     # run i/o benchmark   

  # options specific to scan
  steps = None                          # list, or None to make a linear scan from min_step to max_step
  min_step  =  6                        # minimum is 1
  max_step  = 12                        # None to guess based on the number of available cores (or threads) and concurrent jobs

  ##############################################################################

  # print a system overview
  info()

  if run_io_benchmark :
    print 'Benchmarking only I/O'
    io = copy.deepcopy(process)
    io.hltGetRaw = cms.EDAnalyzer("HLTGetRaw", RawDataCollection = cms.InputTag("rawDataCollector"))
    io.path = cms.Path(io.hltGetRaw)
    io.schedule = cms.Schedule(io.path)
    if 'PrescaleService' in io.__dict__:
      del io.PrescaleService

  # save scan results to 'scan.csv'
  options['data'] = open('scan.csv', 'w', 1)
  options['header'] = True

  # check the available cpus
  cpus = get_cpu_info()
  if options['allow_hyperthreading']:
    count = sum(len(cpu.hardware_threads) for cpu in cpus.values())
  else:
    count = sum(len(cpu.physical_processors) for cpu in cpus.values())

  # use the explicit list of steps, or a linear scan
  if max_step is None:
    max_step = count // options['jobs']

  if not steps:
    steps = range(min_step, max_step + 1)

  # make a copy of the options to be updated during the scan
  step_opt = dict(options)

  options['data'] = open('scan_io.csv', 'w', 1)
  step_opt_io = dict(options)


  for step in steps:
    # update the options for each step
    step_opt['threads'] = options['threads'] if options['threads'] is not None else step
    step_opt['streams'] = options['streams'] if options['streams'] is not None else step
    step_opt['jobs']    = options['jobs']    if options['jobs']    is not None else (count + step - 1) // step

    # run
    if run_io_benchmark :
      print ">>> running I/O <<<"
      # update the options for each step
      step_opt_io['threads'] = options['threads'] if options['threads'] is not None else step
      step_opt_io['streams'] = options['streams'] if options['streams'] is not None else step
      step_opt_io['jobs']    = options['jobs']    if options['jobs']    is not None else (count + step - 1) // step
      # run
      multiCmsRun(io, **step_opt_io)
      print ">>> running config <<<"
      
    multiCmsRun(process, **step_opt)

    # warm up only once
    step_opt['warmup'] = False
    step_opt['header'] = False
